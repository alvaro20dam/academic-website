---
title: 'Predictive Insights: Unraveling Data with Linear Regression in R'
author: Alvaro Gonz
date: '2025-01-20'
slug: predictive-insights-unraveling-data-with-linear-regression-in-r
categories:
  - R
tags:
  - Academic
  - Statistics
subtitle: ''
summary: ''
authors: []
lastmod: '2025-01-20T19:48:10-04:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
output: html_document
---

## Project Introduction

In an era dominated by data, the ability to derive meaningful insights from complex datasets is more crucial than ever. Linear regression stands at the forefront of statistical modeling, offering a powerful yet accessible method for predicting outcomes and understanding relationships between variables. Imagine being able to forecast housing prices, assess the impact of advertising budgets on sales, or even determine factors influencing student performance—all through the lens of a simple mathematical equation. This project delves into the art and science of linear regression in R, illuminating its potential to turn raw data into actionable knowledge.

Join us as we explore the intricacies of building and evaluating linear regression models, while equipping you with the skills to harness this technique for your own data analysis challenges. Whether you're a seasoned data scientist or curious about the analytics world, this journey will unlock the secrets of linear regression, making it an invaluable tool in your analytical toolkit. Let’s embark on this exciting exploration into the transformative power of data-driven decision-making!

### Overview of Linear Regression

Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to observed data. The simplest form, simple linear regression, involves two variables: the dependent variable (y) is predicted based on one independent variable (x) using the formula $y = mx + b$, where m represents the slope of the line and b represents the y-intercept. In multiple linear regression, multiple independent variables are included in the model, extending the formula to $y = b0 + b1x1 + b2x2 + ... + bkxk$.

The key goals of linear regression include understanding the strength and direction of relationships between variables, making predictions, and assessing the importance of various predictors. It relies on assumptions such as linearity, independence, homoscedasticity (constant variance), and normality of errors. The effectiveness of a linear regression model is often evaluated using metrics like R-squared, which indicates the proportion of variance explained by the model, and residual analysis to check for violations of assumptions.

### Importance and Applications in Data Science

Linear regression is crucial in data science due to its simplicity and interpretability, making it a foundational tool for predictive modeling. It helps identify relationships between variables, assess correlations, and make forecasts based on historical data. 

**Applications include:**  
1. **Economics:** Modeling consumer behavior and forecasting economic trends.  
2. **Marketing:** Analyzing advertising effectiveness and customer preferences.  
3. **Healthcare:** Predicting outcomes based on patient data and treatment effects.  
4. **Finance:** Risk assessment and stock price prediction.  
5. **Real Estate:** Estimating property prices based on various features.

Linear regression serves as a valuable starting point for more complex models, enabling data scientists to gain insights, simplify predictive tasks, and communicate findings effectively.

### Objectives of the Project



## Loading the dataset

```{r echo=FALSE}
url <- "https://raw.githubusercontent.com/alejandro-ao/ecommerce-project-r/refs/heads/main/data/customer-data"
data <- read.csv(url)

```

```{r}
str(data)
```
This data contains information about customer characteristics (email, address, avatar color), their engagement metrics (average session length, time spent on app and website), and their purchase behavior (length of membership and yearly amount spent).

```{r}
summary(data)
```


```{r}
library(ggplot2)

# Is there a correlation between Time on Website & Yearly Amount Spent?
ggplot(data, aes(x=Time.on.Website, y=Yearly.Amount.Spent)) + 
  geom_point(colour="orange") + 
  ggtitle("Time on website against vs Yearly amount spent") + 
  xlab("Time on Website") +
  ylab("Yearly Amount Spent")
```

This R code snippet uses the `ggplot2` library to create a scatter plot visualizing the relationship between the average session length of website visits and the yearly amount spent by customers.

Here's a breakdown of the code:

1. **`ggplot(data, aes(x=Avg..Session.Length, y=Yearly.Amount.Spent))`**:
   - This line initiates the ggplot object.
   - `data`: This should be the name of your data frame containing the relevant columns.
   - `aes(x=Avg..Session.Length, y=Yearly.Amount.Spent)`: This specifies the aesthetics of the plot:
     - `x=Avg..Session.Length`: The x-axis variable representing the average session length.
     - `y=Yearly.Amount.Spent`: The y-axis variable representing the yearly amount spent.

2. **`geom_point(colour="orange")`**:
   - This adds points to the plot.
   - `colour="orange"`: Sets the color of the points to orange.

3. **`ggtitle("Average session length against vs Yearly amount spent")`**:
   - Sets the title of the plot.

4. **`xlab("Time on Website")`**:
   - Sets the label for the x-axis.

5. **`ylab("Yearly Amount Spent")`**:
   - Sets the label for the y-axis.

This plot will help you visually explore whether there's a correlation between the time customers spend on your website and the amount they spend annually. You might observe patterns like:

- **Positive correlation:** Customers who spend more time on the website tend to spend more money.
- **Negative correlation:** Customers who spend less time on the website tend to spend more money (which might be unexpected and require further investigation).
- **No correlation:** There's no apparent relationship between session length and yearly spending.

By analyzing this plot, you can gain insights into customer behavior and potentially optimize your website or marketing strategies to encourage more spending.


```{r}
# Is there a correlation between Avg Session Length & Yearly Amount Spent?
ggplot(data, aes(x=Avg..Session.Length, y=Yearly.Amount.Spent)) + 
  geom_point(colour="orange") +
  ggtitle("Average session length against vs Yearly amount spent") + 
  xlab("Time on Website") +
  ylab("Yearly Amount Spent")
```

This R code snippet uses the `ggplot2` library to create a scatter plot visualizing the relationship between the average session length of website visits and the yearly amount spent by customers.

Here's a breakdown of the code:

1. **`ggplot(data, aes(x=Avg..Session.Length, y=Yearly.Amount.Spent))`**:
   - This line initiates the ggplot object.
   - `data`: This should be the name of your data frame containing the relevant columns.
   - `aes(x=Avg..Session.Length, y=Yearly.Amount.Spent)`: This specifies the aesthetics of the plot:
     - `x=Avg..Session.Length`: The x-axis variable representing the average session length.
     - `y=Yearly.Amount.Spent`: The y-axis variable representing the yearly amount spent.

2. **`geom_point(colour="orange")`**:
   - This adds points to the plot.
   - `colour="orange"`: Sets the color of the points to orange.

3. **`ggtitle("Average session length against vs Yearly amount spent")`**:
   - Sets the title of the plot.

4. **`xlab("Time on Website")`**:
   - Sets the label for the x-axis.

5. **`ylab("Yearly Amount Spent")`**:
   - Sets the label for the y-axis.

This plot will help you visually explore whether there's a correlation between the time customers spend on your website and the amount they spend annually. You might observe patterns like:

- **Positive correlation:** Customers who spend more time on the website tend to spend more money.
- **Negative correlation:** Customers who spend less time on the website tend to spend more money (which might be unexpected and require further investigation).
- **No correlation:** There's no apparent relationship between session length and yearly spending.

By analyzing this plot, you can gain insights into customer behavior and potentially optimize your website or marketing strategies to encourage more spending.


```{r}
# pairplot of all continuous variables --> 
#### length of membership seems the most correlated
pairs(data[c("Avg..Session.Length", 
             "Time.on.App", 
             "Time.on.Website", 
             "Length.of.Membership",
             "Yearly.Amount.Spent")],
      col = "orange",
      pch = 16,
      labels = c("Avg Session Length", 
                 "Time on App", 
                 "Time on website",
                 "Length of Membership",
                 "Yearly spent"),
      main = "Pairplot of variables")
```

```{r}
# is the variable normally distributed?
hist(data$Length.of.Membership)
# with ggplot
ggplot(data, aes(x=Length.of.Membership)) + 
  geom_histogram(
    color= "white", 
    fill="orange",
    binwidth = 0.5)

# check distribution with boxplot
boxplot(data$Length.of.Membership)
# with ggplot
ggplot(data, aes(x=Length.of.Membership)) + 
  geom_boxplot(
    fill="orange",
  )
```
```{r}
attach(data)

lm.fit1 <- lm(Yearly.Amount.Spent~Length.of.Membership)

summary(lm.fit1)
# --> p value is below significance level, so the variable Length of 
#     membership is significant.
# --> beta_1 is 64.219, which means that an increase in the variable value
#     causes an increase in the target variable.

plot(Yearly.Amount.Spent~Length.of.Membership)
abline(lm.fit1, col="red")

```

```{r}
qqnorm(residuals(lm.fit1))
qqline(residuals(lm.fit1), col="red")

shapiro.test(residuals(lm.fit1))
# --> the p value is > 0.05 so Ho cannot be rejected. The residuals 
#     distribution is normal.
# --> normality of residuals is an assumption of the linear model.
#     this means that the chosen model works correctly.

```

```{r}
# create a random training and a testing set
set.seed(1)
row.number <- sample(1:nrow(data), 0.8*nrow(data))

train <- data[row.number,]
test <- data[-row.number,]

# estimate the linear fit with the training set
lm.fit0.8 <- lm(Yearly.Amount.Spent~Length.of.Membership, data=train)
summary(lm.fit0.8)

# predict on testing set
prediction0.8 <- predict(lm.fit0.8, newdata = test)
err0.8 <- prediction0.8 - test$Yearly.Amount.Spent
rmse <- sqrt(mean(err0.8^2))
mape <- mean(abs(err0.8/test$Yearly.Amount.Spent))

c(RMSE=rmse,mape=mape,R2=summary(lm.fit0.8)$r.squared) # to print the 3 parameters

```

```{r}
attach(data)
lm.fit <- lm(Yearly.Amount.Spent~Avg..Session.Length +
                                    Time.on.App + 
                                    Time.on.Website +
                                    Length.of.Membership)

summary(lm.fit)

# --------------
# findings :
# 3 of the 4 variables studied seem to have an positive impact on the
# response variable. the most important remains length of membership, with 
# a coefficient 1.5 and 2.4 higher than Time on App and Avg Session Length 
# respectively. 
# Time on website seems to have little impact in the response. 
```
```{r}
# create a random training and a testing set
set.seed(1)
row.number <- sample(1:nrow(data), 0.8*nrow(data))

train <- data[row.number,]
test <- data[-row.number,]

# estimate the linear fit with the training set
multi.lm.fit0.8 <- lm(Yearly.Amount.Spent~Avg..Session.Length +
                        Time.on.App + 
                        Time.on.Website +
                        Length.of.Membership, 
                      data=train)
summary(multi.lm.fit0.8)

# predict on testing set
prediction.multi0.8 <- predict(multi.lm.fit0.8, newdata = test)
err0.8 <- prediction.multi0.8 - test$Yearly.Amount.Spent
rmse <- sqrt(mean(err0.8^2))
mape <- mean(abs(err0.8/test$Yearly.Amount.Spent))

c(RMSE=rmse,mape=mape,R2=summary(lm.fit0.8)$r.squared) # to print the 3 parameters

# --------
# findings
# by using a multiple linear model, we have created a much more accurate
# predictor of the response variable. R2 went from 0.65 to 0.98
# and the RSE went from 47.14 to 9.97 dollars.
```
