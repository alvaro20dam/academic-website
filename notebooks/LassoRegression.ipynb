{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba7e63b3-0a5c-4286-8cca-953aae1f3937",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7c7ea6-5d98-4a1a-b4b1-f427fb2ee0c2",
   "metadata": {},
   "source": [
    "Lasso Regression, short for Least Absolute Shrinkage and Selection Operator, is a linear regression technique that includes regularization to prevent overfitting and perform feature selection.  Here's a breakdown:\r\n",
    "\r\n",
    "**Core Idea:**\r\n",
    "\r\n",
    "Lasso adds a penalty term to the ordinary least squares regression objective function. This penalty is proportional to the absolute value of the coefficients (L1 regularization). This penalty encourages the model to shrink the coefficients of less important features towards zero, and in some cases, can shrink them exactly to zero.\r\n",
    "\r\n",
    "**How it Works:**\r\n",
    "\r\n",
    "1. **Ordinary Least Squares (OLS):**  Traditional linear regression aims to minimize the sum of squared errors between predicted and actual values.\r\n",
    "\r\n",
    "2. **L1 Penalty:** Lasso adds a term that penalizes large coefficients.  The larger the absolute value of a coefficient, the greater the penalty.\r\n",
    "\r\n",
    "3. **Shrinkage:**  During the optimization process, Lasso tries to minimize both the sum of squared errors and the L1 penalty. This leads to shrinking the coefficients.\r\n",
    "\r\n",
    "4. **Feature Selection:** Because the penalty can force coefficients to become exactly zero, Lasso effectively performs feature selection. Features with zero coefficients are excluded from the model.\r\n",
    "\r\n",
    "**What it's Used For:**\r\n",
    "\r\n",
    "* **High-Dimensional Data:** When you have many features (more than samples), Lasso can help identify the most relevant ones and discard the rest, improving model performance and interpretability.\r\n",
    "* **Feature Importance:** Lasso helps understand which features are most influential in predicting the target variable.\r\n",
    "* **Preventing Overfitting:** By shrinking coefficients, Lasso reduces model complexity and prevents it from memorizing noise in the training data, leading to better generalization to unseen data.\r\n",
    "* **Sparse Models:** Lasso produces sparse models (models with many zero coefficients), which are easier to interpret and can be more efficient to compute with.\r\n",
    "\r\n",
    "**In simpler terms:** Imagine you're trying to predict house prices, and you have many features like size, location, age, number of windows, etc. Lasso can help you find the most important factors (maybe size, location, and age) and ignore less relevant ones (like number of windows) to build a simpler, more robust prediction model.\r\n",
    "morm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9860c536-94fd-4cd3-8896-4330bdaafefc",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60256aab-1259-4602-9133-8682dc220ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4037a8-722d-46be-9152-5894d5dc6a35",
   "metadata": {},
   "source": [
    "That's a great start! You've imported all the necessary libraries for performing Lasso Regression. Here's a breakdown of what each import does and why it's important:\r\n",
    "\r\n",
    "*   **`import numpy as np`**: NumPy (Numerical Python) is the fundamental package for numerical computation in Python. It provides powerful array objects (like `np.array`) and tools for working with these arrays.  We import it as `np` for brevity.  NumPy is essential for handling the data in a numerical format that scikit-learn (the machine learning library we'll use) requires.\r\n",
    "\r\n",
    "*   **`import pandas as pd`**: Pandas provides data structures like DataFrames, which are very useful for organizing and manipulating data.  DataFrames allow you to label your data (rows and columns), handle missing values easily, and perform various data transformations.  We import it as `pd`. While not strictly required for the core Lasso Regression, it's highly recommended for data preprocessing and exploration.\r\n",
    "\r\n",
    "*   **`import matplotlib.pyplot as plt`**: Matplotlib is Python's plotting library.  We use it to visualize the data, the model's predictions, and other results.  `plt` is the conventional alias.  Visualizations are crucial for understanding model behavior and results.\r\n",
    "\r\n",
    "*   **`import sklearn.model_selection.train_test_split`**:  `train_test_split` is a function from scikit-learn that allows you to split your data into training and testing sets.  This is a crucial step in machine learning to evaluate how well your model generalizes to unseen data.\r\n",
    "\r\n",
    "*   **`import sklearn.linear_model.Lasso, LassoCV`**:  These are the core imports for Lasso Regression. `Lasso` is the class for performing Lasso regression with a manually chosen regularization parameter (alpha). `LassoCV` is used for Lasso with cross-validation, which automatically finds the best alpha value.\r\n",
    "\r\n",
    "*   **`import sklearn.preprocessing.StandardScaler`**: `StandardScaler` is used for feature scaling.  Lasso is sensitive to the scales of the features, so it's often essential to standardize them (make them have zero mean and unit variance) before applying Lasso.\r\n",
    "\r\n",
    "*   **`import sklearn.metrics.mean_squared_error, r2_score`**: These are the metrics we'll use to evaluate the performance of our Lasso model.  `mean_squared_error` calculates the mean squared difference between the predicted and actual values, and `r2_score` calculates the R-squared coefficient, which represents the proportion of variance in the target variable explained by the model.\r\n",
    "\r\n",
    "With these imports in place, you're ready to proceed with data loading, preprocessing, model training, and evaluation.  You've laid the foundation for a successful Lasso Regression analysis!\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f40733-3d64-4165-af29-956aa022f067",
   "metadata": {},
   "source": [
    "## Data Generation (Synthetic Data)\n",
    "We create synthetic data with a known relationship between features and the target, including some features with zero coefficients to demonstrate feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0e8757c-3c5d-474e-9bc4-7834cba0418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)  # For reproducibility\n",
    "n_samples = 100\n",
    "n_features = 10\n",
    "X = np.random.randn(n_samples, n_features)  # Features\n",
    "true_coeffs = np.array([1, -2, 0.5, 0, 0, 0, 0, 0, 0, 0])  # True coefficients (some are zero)\n",
    "y = X @ true_coeffs + np.random.randn(n_samples) * 0.5  # Target variable with noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d33427-92d2-4b29-b162-e940bc3dcfca",
   "metadata": {},
   "source": [
    "This code snippet generates a synthetic dataset for a regression problem, specifically designed to demonstrate the effects of regularization (like Lasso or Ridge). Let's break down each line:\r\n",
    "\r\n",
    "1. **`np.random.seed(0)`**:\r\n",
    "   - This line sets the seed for NumPy's random number generator.  Setting a seed ensures that the random numbers generated are always the same sequence. This is crucial for reproducibility. If you run this code multiple times, you'll get the exact same dataset every time, which is helpful for debugging and consistent comparisons.\r\n",
    "\r\n",
    "2. **`n_samples = 100`**:\r\n",
    "   - This defines the number of data points (samples) in the dataset.  Here, we're creating a dataset with 100 samples.\r\n",
    "\r\n",
    "3. **`n_features = 10`**:\r\n",
    "   - This sets the number of features (independent variables) for each data point. Each sample will have 10 features.\r\n",
    "\r\n",
    "4. **`X = np.random.randn(n_samples, n_features)`**:\r\n",
    "   - This generates the feature matrix `X`.\r\n",
    "   - `np.random.randn(n_samples, n_features)` creates a 2D array (matrix) of shape (100, 10) filled with random numbers drawn from a standard normal distribution (mean 0, standard deviation 1).  So, `X` is a 100x10 matrix where each row represents a sample and each column represents a feature.\r\n",
    "\r\n",
    "5. **`true_coeffs = np.array([1, -2, 0.5, 0, 0, 0, 0, 0, 0, 0])`**:\r\n",
    "   - This defines the \"true\" coefficients for the underlying relationship between the features and the target variable.  Crucially, notice that most of these coefficients are zero. This is a setup to demonstrate feature selection.  Only the first three features (corresponding to coefficients 1, -2, and 0.5) are actually relevant in determining the target variable.\r\n",
    "\r\n",
    "6. **`y = X @ true_coeffs + np.random.randn(n_samples) * 0.5`**:\r\n",
    "   - This generates the target variable `y`.\r\n",
    "   - `X @ true_coeffs` performs a matrix multiplication of the feature matrix `X` with the `true_coeffs` vector. This calculates the \"true\" underlying relationship.\r\n",
    "   - `np.random.randn(n_samples) * 0.5` adds random noise to the target variable.  `np.random.randn(n_samples)` creates an array of 100 random numbers from a standard normal distribution. Multiplying by 0.5 scales the noise down a bit.  This noise simulates real-world data where there's always some degree of randomness or error.\r\n",
    "\r\n",
    "**In summary:** This code creates a synthetic dataset where:\r\n",
    "\r\n",
    "- There are 100 data points.\r\n",
    "- Each data point has 10 features.\r\n",
    "- The target variable `y` is generated as a linear combination of the first three features (with coefficients 1, -2, and 0.5 respectively) plus some random noise.  The other 7 features are irrelevant (their true coefficients are 0).\r\n",
    "\r\n",
    "This kind of dataset is perfect for demonstrating Lasso regression because Lasso is designed to identify and select the most important features (the ones with non-zero coefficients) and discard the irrelevant ones. You can see how well Lasso can recover the `true_coeffs` despite the added noise.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd4c49b7-c094-4fbb-8bce-9255211238fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Pandas DataFrame for easier handling\n",
    "df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(n_features)])\n",
    "df['target'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63182b8c-ccc0-42c4-9fb6-61197d347b0a",
   "metadata": {},
   "source": [
    "This code snippet takes the NumPy array `X` (containing your features) and the NumPy array `y` (containing your target variable) and creates a Pandas DataFrame called `df`. Let's break it down:\r\n",
    "\r\n",
    "1. **`df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(n_features)])`**:\r\n",
    "   - `pd.DataFrame()` is the Pandas constructor for creating a DataFrame.\r\n",
    "   - `X` is the data that will populate the DataFrame.  Each row of `X` will become a row in the DataFrame, and each column of `X` will become a column in the DataFrame.\r\n",
    "   - `columns=[f'feature_{i}' for i in range(n_features)]` sets the column names.  Let's say `n_features` is 10. This part of the code uses a list comprehension to create a list of strings: `['feature_0', 'feature_1', 'feature_2', ..., 'feature_9']`. This makes your DataFrame more readable and allows you to easily refer to features by name instead of just their column index.\r\n",
    "\r\n",
    "2. **`df['target'] = y`**:\r\n",
    "   - This line adds a new column to the DataFrame `df` called 'target'.  The values in this column are taken from the NumPy array `y`.  So, each row in the DataFrame now has both the original features (from `X`) and the corresponding target value (from `y`).\r\n",
    "\r\n",
    "**Why this is useful:**\r\n",
    "\r\n",
    "- **Labeled Data:** DataFrames provide a way to label your data. Instead of just having a bunch of numbers, you now have a table with meaningful column names (e.g., 'feature_0', 'feature_1', 'target').  This makes your code more readable and less error-prone.\r\n",
    "\r\n",
    "- **Data Manipulation:** Pandas DataFrames provide a wide range of tools for data manipulation, cleaning, and analysis.  You can easily select subsets of your data, filter rows based on conditions, handle missing values, perform calculations on columns, and much more.\r\n",
    "\r\n",
    "- **Scikit-learn Compatibility:** While scikit-learn can work directly with NumPy arrays, it often integrates better with Pandas DataFrames, especially when you start doing more complex things like feature selection, cross-validation, and model evaluation.  It's generally a good practice to organize your data into a DataFrame before working with scikit-learn.\r\n",
    "\r\n",
    "**Example:**\r\n",
    "\r\n",
    "Let's say `X` looks like this (simplified):\r\n",
    "\r\n",
    "```\r\n",
    "X = np.array([[1.0, 2.0],\r\n",
    "              [3.0, 4.0]])\r\n",
    "```\r\n",
    "\r\n",
    "And `y` looks like this:\r\n",
    "\r\n",
    "```\r\n",
    "y = np.array([5.0, 6.0])\r\n",
    "```\r\n",
    "\r\n",
    "After running the code, `df` will look like this:\r\n",
    "\r\n",
    "```\r\n",
    "   feature_0  feature_1  target\r\n",
    "0        1.0        2.0     5.0\r\n",
    "1        3.0        4.0     6.0\r\n",
    "```\r\n",
    "\r\n",
    "Now you have a nicely organized table where each row represents a data point, the first two columns are the features, and the last column is the target variable. You can then easily pass this DataFrame to scikit-learn functions for model training and evaluation.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "084b058b-e8e7-45b9-993d-5e8bcfabc275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Data Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06728e2e-2e02-45c3-9c8f-91682447b0cc",
   "metadata": {},
   "source": [
    "This line of code uses the `train_test_split` function from scikit-learn to divide your dataset into training and testing sets. Let's break it down:\r\n",
    "\r\n",
    "1.  **`X_train, X_test, y_train, y_test = ...`**: This unpacks the output of `train_test_split` into four variables:\r\n",
    "    *   `X_train`: The features for the training set.\r\n",
    "    *   `X_test`: The features for the testing set.\r\n",
    "    *   `y_train`: The target variable for the training set.\r\n",
    "    *   `y_test`: The target variable for the testing set.\r\n",
    "\r\n",
    "2.  **`train_test_split(...)`**: This is the function that performs the splitting.\r\n",
    "\r\n",
    "3.  **`df.drop('target', axis=1)`**: This selects the features (independent variables) from your DataFrame `df`.\r\n",
    "    *   `df.drop('target', axis=1)` creates a new DataFrame that includes all columns from the original DataFrame *except* the 'target' column. `axis=1` specifies that you're dropping a column (not a row).\r\n",
    "\r\n",
    "4.  **`df['target']`**: This selects the target variable (dependent variable) from your DataFrame `df`.\r\n",
    "\r\n",
    "5.  **`test_size=0.2`**: This determines the proportion of the dataset that will be used for testing. Here, 20% of the data will be used for testing, and the remaining 80% will be used for training.\r\n",
    "\r\n",
    "6.  **`random_state=42`**: This sets the seed for the random number generator used by `train_test_split`.  Setting a seed ensures that the data split is reproducible. If you run the code multiple times with the same `random_state`, you'll get the same training and testing sets. This is important for consistency and comparing results.  `42` is a commonly used random state, but you can use any integer.\r\n",
    "\r\n",
    "**Why this is important:**\r\n",
    "\r\n",
    "*   **Training and Testing Sets:** In machine learning, it's crucial to evaluate your model's performance on unseen data.  You train the model on the training set and then evaluate it on the testing set to estimate how well it will generalize to new, real-world data.\r\n",
    "\r\n",
    "*   **Preventing Overfitting:** If you train and evaluate your model on the same data, it can lead to overfitting, where the model performs very well on the training data but poorly on new data.  Splitting the data into training and testing sets helps to avoid this.\r\n",
    "\r\n",
    "*   **Reproducibility:** Setting a `random_state` ensures that your results are reproducible.  This is important for sharing your work and comparing it to others.\r\n",
    "\r\n",
    "**In summary:** This line of code prepares your data for machine learning by splitting it into training and testing sets.  The training set will be used to train your Lasso Regression model, and the testing set will be used to evaluate its performance.  The `random_state` ensures that the split is consistent every time you run the code.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49b1903d-d8d1-4e20-a5c6-b91e2f9a0a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Feature Scaling (Important for Lasso)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # Use the same scaler fitted on the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41473fd0-0855-4301-a2f6-ebf04a1e9e26",
   "metadata": {},
   "source": [
    "This code performs feature scaling using the `StandardScaler` from scikit-learn. Feature scaling is a crucial step for many machine learning algorithms, including Lasso Regression. Here's a breakdown:\r\n",
    "\r\n",
    "1. **`scaler = StandardScaler()`**: This creates an instance of the `StandardScaler`. The `StandardScaler` is a preprocessing tool that standardizes features by removing the mean and scaling to unit variance (i.e., making the mean 0 and the standard deviation 1).\r\n",
    "\r\n",
    "2. **`X_train_scaled = scaler.fit_transform(X_train)`**: This fits the scaler to the training data (`X_train`) and then transforms the training data using the fitted scaler.\r\n",
    "   - `scaler.fit(X_train)`: This calculates the mean and standard deviation of each feature in the training set.  It's crucial to fit the scaler *only* on the training data to avoid data leakage from the test set.\r\n",
    "   - `scaler.transform(X_train)`: This applies the standardization (mean removal and scaling) to the training data using the calculated mean and standard deviation. The result, `X_train_scaled`, is a new NumPy array containing the scaled features for the training set.\r\n",
    "\r\n",
    "3. **`X_test_scaled = scaler.transform(X_test)`**: This transforms the *test* data (`X_test`) using the *same* scaler that was fit on the training data.\r\n",
    "   - **Important:** We use `scaler.transform()` on the test set, *not* `scaler.fit_transform()`.  We don't want to fit the scaler on the test data because that would introduce bias. The test data is meant to simulate unseen, real-world data, and we shouldn't use it to influence the scaling. We use the mean and standard deviation calculated from the training set to scale the test set.\r\n",
    "\r\n",
    "**Why is Feature Scaling Important for Lasso?**\r\n",
    "\r\n",
    "Lasso Regression uses L1 regularization, which adds a penalty proportional to the absolute value of the coefficients.  Features with larger scales can disproportionately influence the regularization process.  If one feature has a much larger range of values than others, Lasso might penalize it more heavily simply because of its scale, not necessarily because it's less important.\r\n",
    "\r\n",
    "Standardizing the features ensures that they all have a similar scale, preventing features with larger ranges from dominating the regularization.  This allows Lasso to fairly compare the importance of different features and apply the regularization more effectively.\r\n",
    "\r\n",
    "**In summary:** This code scales the features in both the training and testing sets using the `StandardScaler`.  It's essential to fit the scaler only on the training data and then use the same fitted scaler to transform the test data. This ensures that the features are on a similar scale, which is crucial for Lasso Regression to perform well.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "274f6b6e-18fc-4b5e-a25e-c4c863407392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Lasso<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Lasso.html\">?<span>Documentation for Lasso</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Lasso(alpha=0.1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Lasso Regression (Manual Alpha Selection)\n",
    "alpha = 0.1  # Regularization strength (you'll need to tune this)\n",
    "lasso = Lasso(alpha=alpha)\n",
    "lasso.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b29bcf6-5452-4cc5-810c-18810927cb8e",
   "metadata": {},
   "source": [
    "This code snippet trains a Lasso Regression model using scikit-learn. Let's break it down:\r\n",
    "\r\n",
    "1. **`alpha = 0.1`**: This line sets the value of the regularization parameter, alpha. Alpha controls the strength of the L1 regularization in Lasso Regression.  It's a hyperparameter that you need to tune (find the best value for your data).\r\n",
    "   - A larger alpha means stronger regularization, which leads to more coefficients being shrunk towards zero (or exactly zero) and simpler models.\r\n",
    "   - A smaller alpha means weaker regularization, making the Lasso model behave more like ordinary least squares regression (less feature selection).\r\n",
    "   - Choosing the right alpha is crucial. We'll discuss how to do this effectively in the next steps (using cross-validation).\r\n",
    "\r\n",
    "2. **`lasso = Lasso(alpha=alpha)`**: This creates an instance (an object) of the `Lasso` class from scikit-learn.  We pass the `alpha` value we just defined to the `Lasso` constructor.  This initializes the Lasso model with the specified regularization strength.\r\n",
    "\r\n",
    "3. **`lasso.fit(X_train_scaled, y_train)`**: This trains (fits) the Lasso model using the training data.\r\n",
    "   - `X_train_scaled`: The scaled features of the training set (important: Lasso works best with scaled features).\r\n",
    "   - `y_train`: The target variable for the training set.\r\n",
    "   - The `fit()` method learns the coefficients that minimize the loss function (sum of squared errors plus the L1 penalty) on the training data.\r\n",
    "\r\n",
    "**In summary:**\r\n",
    "\r\n",
    "This code defines the regularization strength (`alpha`), creates a Lasso model with that alpha, and then trains the model on the scaled training data.  After this step, the `lasso` object will be a trained Lasso model, and you can use it to make predictions on new data.\r\n",
    "\r\n",
    "**Important Note about Alpha Selection:**\r\n",
    "\r\n",
    "The alpha value of 0.1 is just an example.  In practice, you should *not* choose alpha manually like this.  It's highly recommended to use cross-validation (like `LassoCV` in scikit-learn) to automatically find the optimal alpha value for your data.  Cross-validation tries out multiple alpha values and selects the one that gives the best performance on a held-out portion of the training data.  We'll cover that in the next step, as it's a critical part of using Lasso effectively.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27781bfa-e9dc-4be5-8ca0-6f60aec666ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Lasso Regression with Cross-Validation (LassoCV) - Recommended\n",
    "lasso_cv = LassoCV(cv=5)  # 5-fold cross-validation\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "best_alpha = lasso_cv.alpha_  # The optimal alpha found by CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5799738-fccf-4ac5-bac7-871a903f0738",
   "metadata": {},
   "source": [
    "This code snippet uses `LassoCV` (Lasso with Cross-Validation) to automatically find the best value for the regularization parameter, alpha, for your Lasso Regression model. Let's break it down:\r\n",
    "\r\n",
    "1. **`lasso_cv = LassoCV(cv=5)`**:\r\n",
    "   - This creates an instance of the `LassoCV` class.\r\n",
    "   - `cv=5` specifies 5-fold cross-validation.  Cross-validation is a technique for evaluating model performance and selecting hyperparameters (like alpha) by dividing the training data into multiple \"folds.\"  In 5-fold cross-validation, the training data is split into 5 equal parts.  The model is trained 5 times, each time using 4 of the folds as the training set and the remaining fold as the validation set.  The performance is then averaged across the 5 folds.\r\n",
    "\r\n",
    "2. **`lasso_cv.fit(X_train_scaled, y_train)`**:\r\n",
    "   - This trains the `LassoCV` model using the scaled training data.  Crucially, `LassoCV` automatically tries out multiple alpha values (it has a default range it searches over) and performs cross-validation for each alpha.  It keeps track of which alpha value gives the best performance (lowest mean squared error, for example, by default).\r\n",
    "\r\n",
    "3. **`best_alpha = lasso_cv.alpha_`**:\r\n",
    "   - After the `fit()` method completes, `lasso_cv.alpha_` stores the optimal alpha value that was found by cross-validation.  This is the alpha value that gave the best average performance across the 5 folds.  We then store this optimal alpha value in the `best_alpha` variable.\r\n",
    "\r\n",
    "**Why is `LassoCV` Important?**\r\n",
    "\r\n",
    "* **Automatic Alpha Selection:**  Instead of manually trying different alpha values and seeing which one works best, `LassoCV` automates this process.  This is much more efficient and less prone to bias.\r\n",
    "* **Robust Performance Estimate:** Cross-validation provides a more robust estimate of how well the model will perform on unseen data compared to just a single train-test split.  Averaging the performance across multiple folds gives a better sense of the model's generalization ability.\r\n",
    "* **Reduced Overfitting:** By using cross-validation to select alpha, we are less likely to overfit the model to a particular train-test split.\r\n",
    "\r\n",
    "**In summary:**\r\n",
    "\r\n",
    "This code uses `LassoCV` to train a Lasso Regression model and automatically determine the best value for the regularization parameter, alpha, using 5-fold cross-validation. The optimal alpha value is then stored in the `best_alpha` variable.  This is the recommended way to train a Lasso model, as it handles alpha selection in a data-driven and robust manner.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "592f3ee3-4c18-46a1-aa2a-d47bcc89fa84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.027990253782154775)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Lasso<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.Lasso.html\">?<span>Documentation for Lasso</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Lasso(alpha=0.027990253782154775)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.027990253782154775)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit Lasso with the best alpha\n",
    "lasso_best = Lasso(alpha=best_alpha)\n",
    "lasso_best.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfb7826-367c-41c1-ba9c-41301d2c2829",
   "metadata": {},
   "source": [
    "This code creates a final Lasso Regression model using the optimal alpha value (`best_alpha`) that was determined by `LassoCV` in the previous step. Let's break it down:\r\n",
    "\r\n",
    "1. **`lasso_best = Lasso(alpha=best_alpha)`**:\r\n",
    "   - This creates a new instance of the `Lasso` class.\r\n",
    "   - `alpha=best_alpha` sets the regularization strength of this Lasso model to the `best_alpha` value that was found by cross-validation.  This is crucial because we want to use the optimal alpha value for our final model.\r\n",
    "\r\n",
    "2. **`lasso_best.fit(X_train_scaled, y_train)`**:\r\n",
    "   - This trains the final Lasso model (`lasso_best`) using the scaled training data (`X_train_scaled`) and the training target variable (`y_train`).  This is the same training data we used before, but now we're training a regular `Lasso` model with the best alpha we found.\r\n",
    "\r\n",
    "**Why this step is necessary:**\r\n",
    "\r\n",
    "You might wonder why we don't just use the `lasso_cv` object directly since it already \"knows\" the best alpha.  There are a couple of reasons:\r\n",
    "\r\n",
    "* **`LassoCV`'s primary purpose is *finding* the best alpha.** While it does fit a model internally, it's often more efficient to refit a regular `Lasso` model with the optimal alpha.  This can sometimes lead to slight performance improvements or different coefficient values due to how the optimization is carried out.\r\n",
    "* **Clarity and Best Practices:** It's a common and good practice in machine learning to separate the hyperparameter tuning (finding the best alpha using `LassoCV`) from the final model training.  This makes your code more organized and easier to understand.  You clearly see that you've found the best alpha and are now training your final model with that value.\r\n",
    "\r\n",
    "**In summary:**\r\n",
    "\r\n",
    "This code trains the final Lasso Regression model using the optimal regularization strength (`best_alpha`) that was determined by cross-validation.  The resulting `lasso_best` object is the trained model that you should use for making predictions on new, unseen data.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4c4edbd-04c2-45c5-8791-9764c4308583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Model Evaluation\n",
    "# Predictions\n",
    "y_pred_manual = lasso.predict(X_test_scaled)\n",
    "y_pred_cv = lasso_best.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59b6576-c8f9-4697-aeee-099a4e727544",
   "metadata": {},
   "source": [
    "These lines of code use your trained Lasso Regression models to make predictions on the scaled test data. Let's break them down:\r\n",
    "\r\n",
    "1. **`y_pred_manual = lasso.predict(X_test_scaled)`**:\r\n",
    "   - `lasso`: This is your Lasso model that was trained with a manually chosen alpha value (0.1 in the earlier example).  This is *not* the recommended approach, as we should be using cross-validation to select alpha.\r\n",
    "   - `predict(X_test_scaled)`: This method uses the trained `lasso` model to make predictions on the scaled test data (`X_test_scaled`). The output `y_pred_manual` contains the predicted target variable values for each sample in the test set. These predictions are based on the model trained with the manually selected alpha.\r\n",
    "\r\n",
    "2. **`y_pred_cv = lasso_best.predict(X_test_scaled)`**:\r\n",
    "   - `lasso_best`: This is your Lasso model that was trained using the optimal alpha value (`best_alpha`) found by cross-validation (`LassoCV`). This is the model we should be using for evaluation as it's trained with an optimized alpha.\r\n",
    "   - `predict(X_test_scaled)`: This method uses the `lasso_best` model (trained with the best alpha) to make predictions on the same scaled test data. The output `y_pred_cv` contains the predicted target variable values for each sample in the test set. These predictions are based on the model trained with the cross-validated alpha.\r\n",
    "\r\n",
    "**Why we have two sets of predictions:**\r\n",
    "\r\n",
    "The code calculates two sets of predictions to illustrate the difference between using a manually chosen alpha and an alpha selected by cross-validation.  You'll likely see that the `y_pred_cv` predictions (from the model with the cross-validated alpha) are better (have lower error and higher R-squared) than the `y_pred_manual` predictions. This demonstrates the importance of using cross-validation to tune hyperparameters like alpha.\r\n",
    "\r\n",
    "**In summary:**\r\n",
    "\r\n",
    "These lines generate predictions on the scaled test set using both the model trained with a manually chosen alpha (`y_pred_manual`) and the model trained with the cross-validated optimal alpha (`y_pred_cv`).  You would then typically use `y_pred_cv` (the predictions from the cross-validated model) for evaluating your model's performance on unseen data.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cd00302-6a57-432f-9f36-8f2e9e54c994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Lasso:\n",
      "MSE: 0.2651\n",
      "R-squared: 0.9444\n",
      "\n",
      "Lasso with Cross-Validation:\n",
      "Best Alpha: 0.0280\n",
      "MSE: 0.2821\n",
      "R-squared: 0.9408\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "mse_manual = mean_squared_error(y_test, y_pred_manual)\n",
    "r2_manual = r2_score(y_test, y_pred_manual)\n",
    "\n",
    "mse_cv = mean_squared_error(y_test, y_pred_cv)\n",
    "r2_cv = r2_score(y_test, y_pred_cv)\n",
    "\n",
    "print(\"Manual Lasso:\")\n",
    "print(f\"MSE: {mse_manual:.4f}\")\n",
    "print(f\"R-squared: {r2_manual:.4f}\")\n",
    "\n",
    "print(\"\\nLasso with Cross-Validation:\")\n",
    "print(f\"Best Alpha: {best_alpha:.4f}\")\n",
    "print(f\"MSE: {mse_cv:.4f}\")\n",
    "print(f\"R-squared: {r2_cv:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dd7d76-72ff-42e6-8773-6a717131834b",
   "metadata": {},
   "source": [
    "This code calculates and prints the evaluation metrics for both your manually tuned Lasso model and your cross-validated Lasso model. Let's break it down:\r\n",
    "\r\n",
    "1. **`mse_manual = mean_squared_error(y_test, y_pred_manual)`**:\r\n",
    "   - `mean_squared_error(y_test, y_pred_manual)`: This function from scikit-learn calculates the Mean Squared Error (MSE) between the actual target values in the test set (`y_test`) and the predicted target values from your manually tuned Lasso model (`y_pred_manual`).  MSE measures the average squared difference between the predictions and the actual values. Lower MSE is better.\r\n",
    "\r\n",
    "2. **`r2_manual = r2_score(y_test, y_pred_manual)`**:\r\n",
    "   - `r2_score(y_test, y_pred_manual)`: This function calculates the R-squared (R²) score, also known as the coefficient of determination. R² measures the proportion of the variance in the target variable that is predictable from the features.  R² ranges from 0 to 1 (or even negative values for very poor models). Higher R² is better, with 1 indicating a perfect fit.\r\n",
    "\r\n",
    "3. **`mse_cv = mean_squared_error(y_test, y_pred_cv)`**:\r\n",
    "   - Same as above, but now it calculates the MSE between `y_test` and the predictions from your cross-validated Lasso model (`y_pred_cv`).\r\n",
    "\r\n",
    "4. **`r2_cv = r2_score(y_test, y_pred_cv)`**:\r\n",
    "   - Same as above, but calculates the R² score for the cross-validated model's predictions.\r\n",
    "\r\n",
    "5. **`print(...)` statements:** These lines print the calculated MSE and R² values for both models, along with the best alpha found by cross-validation.  The `.4f` in the f-strings formats the output to four decimal places.\r\n",
    "\r\n",
    "**Why evaluate both models?**\r\n",
    "\r\n",
    "By comparing the metrics of the manually tuned model and the cross-validated model, you can see the benefit of using cross-validation.  You should almost always expect the cross-validated model (`lasso_best`) to perform better (lower MSE, higher R²) on the test set because it was trained with an optimized alpha value.  This demonstrates the importance of proper hyperparameter tuning.\r\n",
    "\r\n",
    "**Interpreting the metrics:**\r\n",
    "\r\n",
    "*   **MSE:**  A lower MSE indicates better performance.  It's the average squared difference between the predictions and the actual values, so it's in the units of the target variable squared.\r\n",
    "*   **R²:** A higher R² indicates better performance.  It represents the proportion of variance in the target variable explained by the model.  An R² of 1 is a perfect fit.\r\n",
    "\r\n",
    "By looking at these metrics, you can quantify how well your Lasso Regression model is performing and compare the performance of models trained with different alphas.  The cross-validated model's metrics are the most important, as they represent how well you can expect the model to perform on truly unseen data.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0de148ac-9452-438e-867f-cd767e535bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coefficients (Lasso with CV):\n",
      "Feature 0: 0.9987\n",
      "Feature 1: -1.9436\n",
      "Feature 2: 0.3601\n",
      "Feature 3: 0.1594\n",
      "Feature 4: -0.0513\n",
      "Feature 5: -0.0000\n",
      "Feature 6: 0.0276\n",
      "Feature 7: 0.0000\n",
      "Feature 8: 0.0526\n",
      "Feature 9: -0.0000\n"
     ]
    }
   ],
   "source": [
    "# 7. Coefficient Interpretation\n",
    "coefficients = lasso_best.coef_\n",
    "print(\"\\nCoefficients (Lasso with CV):\")\n",
    "for i, coef in enumerate(coefficients):\n",
    "    print(f\"Feature {i}: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bcd820-cf6d-443e-9810-404a64b7950e",
   "metadata": {},
   "source": [
    "This code snippet extracts and prints the coefficients learned by your trained Lasso Regression model (`lasso_best`), which is the model trained using the optimal alpha found by cross-validation. Let's break it down:\r\n",
    "\r\n",
    "1. **`coefficients = lasso_best.coef_`**:\r\n",
    "   - `lasso_best`: This is your trained Lasso Regression model (the one trained with the best alpha from cross-validation).\r\n",
    "   - `coef_`: This is an attribute of the trained Lasso model that stores the learned coefficients.  It's a NumPy array where each element corresponds to the coefficient of a feature.\r\n",
    "\r\n",
    "2. **`print(\"\\nCoefficients (Lasso with CV):\")`**: This simply prints a header to indicate what the following output represents. The `\\n` creates a new line for better readability.\r\n",
    "\r\n",
    "3. **`for i, coef in enumerate(coefficients):`**:\r\n",
    "   - This loop iterates through the `coefficients` array.\r\n",
    "   - `enumerate(coefficients)`: This function returns pairs of (index, value) for each element in the `coefficients` array.  `i` will be the index (0, 1, 2, ...), and `coef` will be the coefficient value for that feature.\r\n",
    "\r\n",
    "4. **`print(f\"Feature {i}: {coef:.4f}\")`**:\r\n",
    "   - Inside the loop, this line prints the feature index (`i`) and its corresponding coefficient (`coef`).\r\n",
    "   - `f\"Feature {i}: {coef:.4f}\"`: This is an f-string (formatted string literal) that allows you to embed variables directly in strings.  `{coef:.4f}` formats the coefficient value to four decimal places.\r\n",
    "\r\n",
    "**Why are the coefficients important?**\r\n",
    "\r\n",
    "The coefficients tell you the relationship between each feature and the target variable.\r\n",
    "\r\n",
    "*   **Magnitude:** The magnitude (absolute value) of a coefficient indicates the importance of the feature. Larger coefficients mean the feature has a stronger influence on the target variable.\r\n",
    "*   **Sign:** The sign (positive or negative) of a coefficient indicates the direction of the relationship. A positive coefficient means that an increase in the feature's value leads to an increase in the target variable (and vice versa for negative coefficients).\r\n",
    "*   **Zero Coefficients:** One of the key benefits of Lasso is that it can shrink coefficients to exactly zero.  A zero coefficient means that the feature is effectively excluded from the model, indicating that it's not important for predicting the target variable.  This is how Lasso performs feature selection.\r\n",
    "\r\n",
    "**Interpreting the Output:**\r\n",
    "\r\n",
    "The output will look something like this:\r\n",
    "\r\n",
    "```\r\n",
    "Coefficients (Lasso with CV):\r\n",
    "Feature 0: 0.8532\r\n",
    "Feature 1: -1.9213\r\n",
    "Feature 2: 0.4276\r\n",
    "Feature 3: 0.0000\r\n",
    "Feature 4: -0.0000\r\n",
    "Feature 5: 0.0000\r\n",
    "Feature 6: 0.0000\r\n",
    "Feature 7: 0.0000\r\n",
    "Feature 8: 0.0000\r\n",
    "Feature 9: 0.0000\r\n",
    "```\r\n",
    "\r\n",
    "Notice how some of the coefficients are exactly zero. This means that Lasso has selected only the first three features (0, 1, and 2) as being relevant, and it has effectively discarded the other features.  This demonstrates feature selection. You can also see the magnitude and sign of the coefficients to understand how each selected feature influences the target variable.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2741b7a2-e309-4bcc-bb33-e132f4056d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 8. Plotting (Optional)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_test_scaled[:, 0], y_test, label='Actual')  # Plot against the first feature (just for visualization)\n",
    "plt.scatter(X_test_scaled[:, 0], y_pred_cv, label='Predicted (CV)')\n",
    "plt.xlabel('Scaled Feature 0')\n",
    "plt.ylabel('Target')\n",
    "plt.legend()\n",
    "plt.title('Lasso Regression Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c306e521-68d2-48bf-a9f4-f49896d80cbf",
   "metadata": {},
   "source": [
    "This code generates a scatter plot to visualize the performance of your Lasso Regression model on the test set. Let's break it down:\r\n",
    "\r\n",
    "1. **`plt.figure(figsize=(10, 6))`**: This creates a new Matplotlib figure with a specified size of 10 inches wide and 6 inches tall.  This is just setting up the canvas for your plot.\r\n",
    "\r\n",
    "2. **`plt.scatter(X_test_scaled[:, 0], y_test, label='Actual')`**:\r\n",
    "   - `plt.scatter()`: This function creates a scatter plot.\r\n",
    "   - `X_test_scaled[:, 0]`: This selects the first feature (index 0) from your scaled test data.  We're plotting the actual target values against just the first feature for visualization purposes (it's hard to visualize in more than two dimensions).\r\n",
    "   - `y_test`: These are the actual target values from the test set.\r\n",
    "   - `label='Actual'`: This sets the label for this set of points in the legend.\r\n",
    "\r\n",
    "3. **`plt.scatter(X_test_scaled[:, 0], y_pred_cv, label='Predicted (CV)')`**:\r\n",
    "   - This creates another scatter plot, but now for the predicted target values.\r\n",
    "   - `y_pred_cv`: These are the predicted target values from your cross-validated Lasso model.\r\n",
    "   - `label='Predicted (CV)'`: This sets the label for the predicted points in the legend.\r\n",
    "\r\n",
    "4. **`plt.xlabel('Scaled Feature 0')`**: This sets the label for the x-axis (the first scaled feature).\r\n",
    "\r\n",
    "5. **`plt.ylabel('Target')`**: This sets the label for the y-axis (the target variable).\r\n",
    "\r\n",
    "6. **`plt.legend()`**: This displays the legend, which shows the labels for the actual and predicted points.\r\n",
    "\r\n",
    "7. **`plt.title('Lasso Regression Results')`**: This sets the title of the plot.\r\n",
    "\r\n",
    "8. **`plt.show()`**: This displays the plot.\r\n",
    "\r\n",
    "**What you'll see:**\r\n",
    "\r\n",
    "The plot will show two sets of points:\r\n",
    "\r\n",
    "*   **\"Actual\" points (usually in blue):** These represent the true target values from your test set, plotted against the first feature.\r\n",
    "*   **\"Predicted (CV)\" points (usually in orange):** These represent the target values predicted by your Lasso model, also plotted against the first feature.\r\n",
    "\r\n",
    "**Interpreting the plot:**\r\n",
    "\r\n",
    "Ideally, the \"Predicted (CV)\" points should be close to the \"Actual\" points.  The closer they are, the better your model is performing.  If the predicted points form a clear pattern or trend that matches the actual points, it suggests that your model has captured the underlying relationship between the features and the target variable well.\r\n",
    "\r\n",
    "**Important Note:**\r\n",
    "\r\n",
    "This plot only visualizes the relationship with the *first* feature.  If you have more than one feature (which is usually the case), it's difficult to visualize the full relationship in a single 2D plot.  However, this plot can still give you a general idea of how well your model is doing, especially if the first feature is one of the most important ones (as it often is in these illustrative examples).  For higher dimensional data, you'd rely more on the evaluation metrics (MSE, R-squared) to assess the model's performance.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e642c8f-be49-47f9-99f9-d996ac9d8969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions on New Data:\n",
      "[ 2.13671242  1.06649449  2.12228194 -0.46738376 -1.76623559]\n"
     ]
    }
   ],
   "source": [
    "# Example of how to use the model for prediction on new data\n",
    "new_data = pd.DataFrame(np.random.randn(5, n_features), columns=[f'feature_{i}' for i in range(n_features)])\n",
    "new_data_scaled = scaler.transform(new_data)  # Scale the new data using the same scaler\n",
    "predictions = lasso_best.predict(new_data_scaled)\n",
    "print(\"\\nPredictions on New Data:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13061f7a-6752-4a9c-8e70-78440b2fc973",
   "metadata": {},
   "source": [
    "This code snippet demonstrates how to use your trained Lasso Regression model (`lasso_best`) to make predictions on entirely new, unseen data. Let's break it down:\r\n",
    "\r\n",
    "1. **`new_data = pd.DataFrame(np.random.randn(5, n_features), columns=[f'feature_{i}' for i in range(n_features)])`**:\r\n",
    "   - This creates a new Pandas DataFrame called `new_data` to represent your unseen data.\r\n",
    "   - `np.random.randn(5, n_features)`: This generates a NumPy array with 5 rows (representing 5 new data points) and `n_features` columns (the same number of features as your original data). The values are drawn from a standard normal distribution (mean 0, standard deviation 1).  **Important:** In a real-world scenario, you would replace this with your actual new data.\r\n",
    "   - `columns=[f'feature_{i}' for i in range(n_features)]`: This sets the column names of the DataFrame to match the names of your original features (e.g., 'feature_0', 'feature_1', etc.).  This is essential for consistency.\r\n",
    "\r\n",
    "2. **`new_data_scaled = scaler.transform(new_data)`**:\r\n",
    "   - This scales the new data using the *same* `StandardScaler` that you fit on the training data.  **Crucially**, you *must* use the same scaler that was used for training.  You should *not* fit a new scaler on the new data.  This ensures that the new data is scaled in the same way as the data the model was trained on.\r\n",
    "\r\n",
    "3. **`predictions = lasso_best.predict(new_data_scaled)`**:\r\n",
    "   - This uses your trained Lasso Regression model (`lasso_best`, the one trained with the optimal alpha) to make predictions on the scaled new data (`new_data_scaled`).  The result, `predictions`, is a NumPy array containing the predicted target variable values for each of the 5 new data points.\r\n",
    "\r\n",
    "4. **`print(\"\\nPredictions on New Data:\")`**: This simply prints a header to indicate what the following output represents.\r\n",
    "\r\n",
    "5. **`print(predictions)`**: This prints the array of predictions.\r\n",
    "\r\n",
    "**Key Points and Best Practices:**\r\n",
    "\r\n",
    "* **Consistent Scaling:**  It's absolutely essential to scale your new data using the *same* `StandardScaler` (or whatever scaler you used) that was fit on your training data.  Don't fit a new scaler on the new data.\r\n",
    "* **Data Format:**  The new data should have the same number of features and the same feature names (or column order if you're using NumPy arrays directly) as your training data.\r\n",
    "* **Real-World Data:**  In a real application, you would replace the `np.random.randn(5, n_features)` part with your actual new data, which you would load from a file or receive from some other source.\r\n",
    "* **Prediction Interpretation:** The `predictions` array contains the predicted target variable values for your new data points.  You can then use these predictions for whatever purpose you need them for (e.g., making business decisions, forecasting, etc.).\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
